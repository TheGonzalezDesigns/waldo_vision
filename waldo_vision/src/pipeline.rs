// THEORY:
// The `pipeline` module is the final, top-level API for the entire vision engine.
// It encapsulates the full architectural stack (`GridManager`, `BlobDetector`,
// `SceneManager`) into a single, easy-to-use interface.
//
// Its purpose is to provide a clean and user-friendly entry point for processing
// image data and receiving high-level, actionable reports about significant events.
//
// Key architectural principles:
// 1.  **Encapsulation**: The `VisionPipeline` struct owns and manages all the complex
//     underlying components. A user of this library only needs to interact with this
//     single struct.
// 2.  **Dual-Purpose API**: It provides two distinct methods for different use cases:
//     - `significant_mention_detected`: A simple, high-performance boolean check
//       ideal for real-time loops (e.g., WebSocket pipelines) where only a "go/no-go"
//       signal is needed.
//     - `generate_report`: A richer method that provides a detailed `Report` enum,
//       containing the full data of any detected `Moment`s for deeper analysis.
// 3.  **Tunable Configuration**: It uses a `PipelineConfig` struct to hold key
//     thresholds, allowing users to easily tune the sensitivity and behavior of the
//     filter without needing to understand the internal algorithms.
// 4.  **Final Decision Logic**: This is the layer where the final "judgment call" is
//     made. It analyzes the output of the `SceneManager` and uses the configuration
//     to decide what constitutes a "significant mention."

use crate::core_modules::blob_detector::blob_detector;
use crate::core_modules::grid_manager::GridManager;
use crate::core_modules::moment::SceneManager;
use crate::core_modules::smart_blob::SmartBlob;
use std::collections::VecDeque;

// Re-export key data structures for the public API.
pub use crate::core_modules::moment::Moment;
pub use crate::core_modules::smart_chunk::{AnomalyDetails, ChunkStatus};

const BLOB_SIZE_HISTORY_LENGTH: usize = 100; // Keep a history of the last 100 blob sizes.

/// Configuration for the VisionPipeline, allowing for tunable behavior.
#[derive(Debug, Clone)]
pub struct PipelineConfig {
    /// The width of the incoming video frames, in pixels.
    pub image_width: u32,
    /// The height of the incoming video frames, in pixels.
    pub image_height: u32,
    /// The width of a single chunk, in pixels. A 10x10 grid is a good starting point.
    pub chunk_width: u32,
    /// The height of a single chunk, in pixels.
    pub chunk_height: u32,
    /// A `Moment` is only reported as significant if it's a "birth" event younger than this many frames.
    /// This captures the initial appearance of an object.
    pub significance_age_threshold: u32,
    /// The statistical filter for blob size. A blob will be discarded if its size (in chunks)
    /// is more than this many standard deviations below the mean of recent blob sizes.
    pub blob_size_std_dev_filter: f64,
    /// The absolute minimum number of chunks a `SmartBlob` must contain to not be
    /// immediately discarded as noise. This is the first stage of blob filtering.
    pub absolute_min_blob_size: usize,
}

/// The detailed data package for a significant event, returned by the `VisionPipeline`.
#[derive(Debug, Clone)]
pub struct MentionData {
    /// A list of `Moment`s that were newly created in the last processed frame
    /// and which meet the significance criteria defined in the `PipelineConfig`.
    pub new_significant_moments: Vec<Moment>,
    /// A list of `Moment`s that were completed (i.e., the object disappeared)
    /// in the last processed frame and which meet the significance criteria.
    pub completed_significant_moments: Vec<Moment>,
}

/// The primary output of the vision pipeline for a single frame.
/// This enum provides a clear, top-level result of the analysis.
#[derive(Debug, Clone)]
pub enum Report {
    /// Indicates that no events meeting the significance criteria were detected.
    NoSignificantMention,
    /// Indicates that one or more significant events occurred.
    /// Contains the detailed `MentionData` for the event(s).
    SignificantMention(MentionData),
}

/// The main, top-level struct for the vision engine.
/// This struct encapsulates and orchestrates the entire vision pipeline.
pub struct VisionPipeline {
    /// The `GridManager` owns the grid of `SmartChunk`s and handles the temporal analysis.
    grid_manager: GridManager,
    /// The `SceneManager` owns the `Tracker` and handles the behavioral analysis.
    scene_manager: SceneManager,
    /// The configuration that tunes the pipeline's sensitivity and behavior.
    config: PipelineConfig,
    /// The most recent status map generated by the `GridManager`, cached for visualization.
    last_status_map: Vec<ChunkStatus>,
    /// A sliding window history of recent, valid blob sizes, used for statistical noise filtering.
    blob_size_history: VecDeque<usize>,
}

impl VisionPipeline {
    /// Creates a new, configured instance of the vision pipeline.
    pub fn new(config: PipelineConfig) -> Self {
        let grid_manager = GridManager::new(
            config.image_width,
            config.image_height,
            config.chunk_width,
            config.chunk_height,
        );
        let num_chunks = (config.image_width / config.chunk_width) * (config.image_height / config.chunk_height);
        Self {
            grid_manager,
            scene_manager: SceneManager::new(),
            config,
            last_status_map: vec![ChunkStatus::Learning; num_chunks as usize],
            blob_size_history: VecDeque::with_capacity(BLOB_SIZE_HISTORY_LENGTH),
        }
    }

    /// Processes a frame and returns a simple boolean indicating if a significant event occurred.
    pub fn significant_mention_detected(&mut self, frame_buffer: &[u8]) -> bool {
        let report = self.generate_report(frame_buffer);
        matches!(report, Report::SignificantMention(_))
    }

    /// Processes a frame and returns a detailed report of all significant events.
    pub fn generate_report(&mut self, frame_buffer: &[u8]) -> Report {
        // Stage 1: Temporal Analysis
        self.last_status_map = self.grid_manager.process_frame(frame_buffer);

        // Stage 2: Spatial Grouping
        let raw_blobs = blob_detector::find_blobs(
            &self.last_status_map,
            self.config.image_width / self.config.chunk_width,
            self.config.image_height / self.config.chunk_height,
        );

        // Stage 2.5: Production-Ready Blob Filtering
        let filtered_blobs = self.filter_blobs(raw_blobs);

        // Stage 3: Behavioral Analysis
        let (newly_started, newly_completed) = self.scene_manager.update(filtered_blobs);

        // Stage 4: Final, Tracker-Aware Decision Logic
        let new_significant_moments: Vec<Moment> = newly_started
            .iter()
            .filter(|m| self.is_moment_significant(m))
            .cloned()
            .collect();

        // For now, we only report on new moments. Completed moments could be added later.
        let completed_significant_moments: Vec<Moment> = Vec::new();

        if new_significant_moments.is_empty() && completed_significant_moments.is_empty() {
            Report::NoSignificantMention
        } else {
            Report::SignificantMention(MentionData {
                new_significant_moments,
                completed_significant_moments,
            })
        }
    }

    /// Applies a multi-stage filtering process to raw blobs to remove noise.
    fn filter_blobs(&mut self, blobs: Vec<SmartBlob>) -> Vec<SmartBlob> {
        let (mean, std_dev) = {
            if self.blob_size_history.is_empty() { (0.0, 0.0) } else {
                let sum: usize = self.blob_size_history.iter().sum();
                let mean = sum as f64 / self.blob_size_history.len() as f64;
                let variance = self.blob_size_history.iter()
                    .map(|value| (*value as f64 - mean).powi(2))
                    .sum::<f64>() / self.blob_size_history.len() as f64;
                (mean, variance.sqrt())
            }
        };

        let mut filtered_blobs = Vec::new();
        for blob in blobs {
            if blob.size_in_chunks < self.config.absolute_min_blob_size { continue; }
            if self.blob_size_history.len() >= BLOB_SIZE_HISTORY_LENGTH / 2 {
                let threshold = mean - self.config.blob_size_std_dev_filter * std_dev;
                if (blob.size_in_chunks as f64) < threshold { continue; }
            }
            filtered_blobs.push(blob);
        }

        for blob in &filtered_blobs {
            if self.blob_size_history.len() >= BLOB_SIZE_HISTORY_LENGTH {
                self.blob_size_history.pop_front();
            }
            self.blob_size_history.push_back(blob.size_in_chunks);
        }
        filtered_blobs
    }

    /// Analyzes a moment to determine if it's significant based on tracker-aware logic.
    fn is_moment_significant(&self, moment: &Moment) -> bool {
        // The primary rule for significance: is this a "birth" event?
        // We consider a moment significant if it's new (i.e., its age is very young).
        // This captures the initial appearance of an object, which is the most important event.
        // We no longer need to check every blob in the history, which solves the re-triggering issue.
        let age = moment.end_frame - moment.start_frame;
        age <= self.config.significance_age_threshold as u64
    }

    /// Returns a slice of the ChunkStatus map from the most recently processed frame.
    pub fn get_last_status_map(&self) -> &[ChunkStatus] {
        &self.last_status_map
    }
}